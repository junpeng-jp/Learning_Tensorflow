{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "racial-pharmaceutical",
   "metadata": {},
   "source": [
    "# Rock, Paper, Scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-somalia",
   "metadata": {},
   "source": [
    "**Import Custom Scripts [Local Notebook]**\n",
    "\n",
    "Use this import if you are running the notebook locally from the root directory of the github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from lib.image_transforms import stateless_random_rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-summit",
   "metadata": {},
   "source": [
    "**Import Custom Scripts [Google Colab]**\n",
    "\n",
    "To use the custom scripts in Google Colab, clone the git repository to your local directory and use an absolute import statement.\n",
    "\n",
    "Check out `./learning_tf/lib` for the custom functions used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow-addons\n",
    "# ! git clone https://github.com/junpeng-jp/learning_tensorflow ./learning_tensorflow\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "# import tensorflow_addons as tfa\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# from learning_tensorflow.lib.image_transforms import stateless_random_rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-three",
   "metadata": {},
   "source": [
    "## Downloading Dataset\n",
    "\n",
    "Tensorflow datasets is a library that provides user-friendly APIs to download many datasets available online. A convenient Split API is included that will split the downloaded files into `tf.record` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = tfds.builder(\n",
    "    'rock_paper_scissors',\n",
    "    data_dir = \"./data\")\n",
    "\n",
    "builder.download_and_prepare()\n",
    "\n",
    "train, test = builder.as_dataset(\n",
    "    split = ['train', 'test'],\n",
    "    shuffle_files = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = builder.info.features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23916481831\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-cancer",
   "metadata": {},
   "source": [
    "## Classifying CG Hands\n",
    "\n",
    "The dataset provided uses a images of hands that were generated using computer graphics software. Most of the hand poses are slight variations in angles of a base CG hand and can potentially introduce some biases into the convolution model that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(8,8))\n",
    "fig.tight_layout()\n",
    "\n",
    "for ax, data in zip(axes.ravel(), train.take(16)):\n",
    "    ax.imshow(data['image'].numpy())\n",
    "    ax.set_title(\"{}\".format(label_encoder.int2str(data['label'])))\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (300, 300)\n",
    "DELTA_ROTATE = 45\n",
    "DELTA_BRIGHTNESS = 0.2\n",
    "DELTA_HUE = 0.5\n",
    "DELTA_SATURATION = (0.8, 1.2)\n",
    "rng = tf.random.Generator.from_seed(seed)\n",
    "\n",
    "def standardize_img(data):\n",
    "    image, label = data['image'], data['label']\n",
    "    image = tf.cast(image, tf.float64) / 255.\n",
    "    image = tf.image.resize(image, IMG_SIZE) \n",
    "    label = tf.one_hot(label, depth = 3)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def augmentation(image, label):\n",
    "    rng_seed = rng.make_seeds(1)[:, 0]\n",
    "    \n",
    "    image = tf.image.stateless_random_brightness(image, DELTA_BRIGHTNESS, seed = rng_seed)\n",
    "    image = tf.image.stateless_random_flip_left_right(image, seed = rng_seed)\n",
    "    image = tf.image.stateless_random_flip_up_down(image, seed = rng_seed)\n",
    "    image = stateless_random_rotate(image, DELTA_ROTATE, seed = rng_seed, fill_value=0)\n",
    "    image = tf.image.stateless_random_saturation(image, *DELTA_SATURATION, seed = rng_seed)\n",
    "    image = tf.clip_by_value(image, 0, 1)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "trainloader = (\n",
    "    train\n",
    "    .shuffle(1000)\n",
    "    .map(standardize_img, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(augmentation, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "testloader = (\n",
    "    test\n",
    "    .map(standardize_img, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(8,8))\n",
    "fig.tight_layout()\n",
    "\n",
    "for img, label in trainloader.take(1):\n",
    "    label = tf.argmax(label, axis = 1)\n",
    "    for ax, i in zip(axes.ravel(), range(16)):\n",
    "        ax.imshow(img[i].numpy())\n",
    "        ax.set_title(\"{}\".format(label_encoder.int2str(label[i])))\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(*IMG_SIZE, 3)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tfa.optimizers.AdamW(weight_decay=1e-6, learning_rate=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer, \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    trainloader,\n",
    "    validation_data = testloader,\n",
    "    epochs = 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learning Tensorflow",
   "language": "python",
   "name": "learning_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
